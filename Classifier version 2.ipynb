{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "Classifier biult on transformer-based RoBERTa-base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('train-claims.json', 'r') as f:\n",
        "  train_claims_data = json.load(f)\n",
        "\n",
        "with open('dev-claims.json', 'r') as f:\n",
        "  train_labels_data = json.load(f)\n",
        "\n",
        "with open('test-claims-unlabelled.json', 'r') as f:\n",
        "  dev_claims_data = json.load(f)\n",
        "\n",
        "with open('evidence.json', 'r') as f:\n",
        "  evidence_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Co39n2Vs8Ic",
        "outputId": "9d2e36d8-b379-41fb-af65-21ff254c3355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total claims: 1228\n",
            "Label distribution: Counter({'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124})\n",
            "Claim length - max: 67, min: 4, mean: 20.10\n",
            "Evidence count per claim - max: 5, min: 1, mean: 3.36\n",
            "Evidence text length - max: 276, min: 3, mean: 27.63\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Prepare statistics\n",
        "claim_lengths = []\n",
        "evidence_lengths = []\n",
        "evidence_counts = []\n",
        "labels = []\n",
        "\n",
        "label_counter = Counter()\n",
        "\n",
        "for claim_id, claim_data in train_claims_data.items():\n",
        "    claim = claim_data[\"claim_text\"]\n",
        "    label = claim_data[\"claim_label\"]\n",
        "    evid_ids = claim_data.get(\"evidences\", [])\n",
        "\n",
        "    claim_lengths.append(len(claim.split()))\n",
        "    evidence_counts.append(len(evid_ids))\n",
        "    labels.append(label)\n",
        "    label_counter[label] += 1\n",
        "\n",
        "    for evid_id in evid_ids:\n",
        "        if evid_id in evidence_data:\n",
        "            ev_text = evidence_data[evid_id]\n",
        "            evidence_lengths.append(len(ev_text.split()))\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"Total claims: {len(train_claims_data)}\")\n",
        "print(f\"Label distribution: {label_counter}\")\n",
        "print(f\"Claim length - max: {max(claim_lengths)}, min: {min(claim_lengths)}, mean: {np.mean(claim_lengths):.2f}\")\n",
        "print(f\"Evidence count per claim - max: {max(evidence_counts)}, min: {min(evidence_counts)}, mean: {np.mean(evidence_counts):.2f}\")\n",
        "print(f\"Evidence text length - max: {max(evidence_lengths)}, min: {min(evidence_lengths)}, mean: {np.mean(evidence_lengths):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1YBn4Kz248o"
      },
      "outputs": [],
      "source": [
        "Vector Embedding Using BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJBC2kBx0gzG"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedder = SentenceTransformer('all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AsBwoqIIjz_"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "claim_texts = [claim[\"claim_text\"] for claim in train_claims_data.values()]\n",
        "claim_ids = list(train_claims_data.keys())\n",
        "\n",
        "evid_ids = list(evidence_data.keys())\n",
        "evid_texts = [evidence_data[eid] for eid in evid_ids]\n",
        "\n",
        "evid_texts = evid_texts[:50000]\n",
        "evid_ids = evid_ids[:50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0WW7muW6Qpj4"
      },
      "outputs": [],
      "source": [
        "claim_vecs = embedder.encode(\n",
        "    claim_texts,\n",
        "    batch_size=64,\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True,\n",
        ")\n",
        "\n",
        "evid_vecs = embedder.encode(\n",
        "    evid_texts,\n",
        "    batch_size=64,\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "862aeFqt21-f"
      },
      "outputs": [],
      "source": [
        "Pre-Ranking via Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RIJp8Z2rufue"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "claim_vecs_np = claim_vecs.detach().cpu().numpy()\n",
        "evid_vecs_np = evid_vecs.detach().cpu().numpy()\n",
        "\n",
        "similarity_matrix = cosine_similarity(claim_vecs_np, evid_vecs_np)\n",
        "\n",
        "k = 5\n",
        "top_k_idx = np.argsort(similarity_matrix, axis=1)[:, -k:][:, ::-1]\n",
        "\n",
        "top_k_matches = {\n",
        "    claim_ids[i]: [evid_ids[j] for j in top_k_idx[i]]\n",
        "    for i in range(len(claim_ids))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaGLjur4CCFV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "label_map = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n",
        "\n",
        "pair_data = []\n",
        "\n",
        "for cid in claim_ids:\n",
        "  claim = train_claims_data[cid]\n",
        "  claim_text = claim[\"claim_text\"]\n",
        "  label_str = claim[\"claim_label\"]\n",
        "  true_label = label_map[label_str]\n",
        "  pos_evids = claim.get(\"evidences\", [])\n",
        "  candidate_evids = top_k_matches[cid]\n",
        "\n",
        "  for evid in candidate_evids:\n",
        "    if evid in pos_evids and evid in evidence_data:\n",
        "      text = claim_text + \" [SEP] \" + evidence_data[evid]\n",
        "      pair_data.append({\"text\": text, \"label\": true_label})\n",
        "\n",
        "  for evid in candidate_evids:\n",
        "    if evid not in pos_evids and evid in evidence_data:\n",
        "      # Assign DISPUTED to simulate semantically confusing distractor\n",
        "      text = claim_text + \" [SEP] \" + evidence_data[evid]\n",
        "      pair_data.append({\"text\": text, \"label\": 3})  # DISPUTED\n",
        "\n",
        "  neg_pool = list(set(evidence_data.keys()) - set(pos_evids) - set(candidate_evids))\n",
        "  neg_samples = random.sample(neg_pool, min(2, len(neg_pool)))\n",
        "  for evid in neg_samples:\n",
        "    if evid in evidence_data:\n",
        "      text = claim_text + \" [SEP] \" + evidence_data[evid]\n",
        "      pair_data.append({\"text\": text, \"label\": 2})  # NOT_ENOUGH_INFO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0MxFCyH25Dk"
      },
      "outputs": [],
      "source": [
        "for example in pair_data:\n",
        "  if random.random() < 0.2:\n",
        "    current = example[\"label\"]\n",
        "    example[\"label\"] = random.choice([l for l in range(4) if l != current])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AgJTrsHOxqI"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "\n",
        "labels = [example[\"label\"] for example in pair_data]\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(labels),\n",
        "                                     y=labels)\n",
        "\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(model.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Ghj-cwhpgD"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import torch.nn as nn\n",
        "\n",
        "class WeightedLossTrainer(Trainer):\n",
        "  def __init__(self, class_weights_tensor, *args, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "\n",
        "  def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "    labels = inputs.pop(\"labels\")\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    loss = self.loss_fn(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
        "    return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HFGDu30pKB4u"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65T610iPLXfH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG4vNnpOujXa"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import Dataset\n",
        "\n",
        "model_name = \"distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
        "\n",
        "dataset = Dataset.from_list(pair_data)\n",
        "\n",
        "def preprocess(example):\n",
        "  return tokenizer(example['text'], truncation=True, padding='max_length')\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess, batched=True)\n",
        "\n",
        "# Train/test split\n",
        "split_data = encoded_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = split_data[\"train\"]\n",
        "eval_dataset = split_data[\"test\"]\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./bert-reranker\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    logging_first_step=True,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = WeightedLossTrainer(\n",
        "    class_weights_tensor=class_weights_tensor,\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj43Qoa8GOVj"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "y_train = [item[\"label\"] for item in pair_data]\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb-G_dMKCiNy"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"bert-classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iMkjqgn9NYH"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Get model predictions\n",
        "outputs = trainer.predict(eval_dataset)\n",
        "y_pred = np.argmax(outputs.predictions, axis=1)\n",
        "y_true = outputs.label_ids\n",
        "\n",
        "label_map = {0: \"SUPPORTS\", 1: \"REFUTES\", 2: \"NOT_ENOUGH_INFO\", 3: \"DISPUTED\"}\n",
        "target_names = [label_map[i] for i in sorted(label_map)]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=target_names, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGxFMtke-9Nk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Binarize the output\n",
        "y_true_bin = label_binarize(y_true, classes=[0, 1, 2, 3])\n",
        "y_score = outputs.predictions  # Raw scores from the model\n",
        "\n",
        "# Plot precision-recall curve for each class\n",
        "for i in range(len(label_map)):\n",
        "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_score[:, i])\n",
        "    plt.plot(recall, precision, label=label_map[i])\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1kt-JqT_qzJ"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "label_map = {\"SUPPORTS\": 0, \"REFUTES\": 1, \"NOT_ENOUGH_INFO\": 2, \"DISPUTED\": 3}\n",
        "\n",
        "eval_pair_data = []\n",
        "for cid, claim_obj in train_labels_data.items():\n",
        "  claim_text = claim_obj[\"claim_text\"]\n",
        "  label_str = claim_obj[\"claim_label\"]\n",
        "  label = label_map[label_str]\n",
        "  for evid_id in claim_obj[\"evidences\"]:\n",
        "    if evid_id in evidence_data:\n",
        "      evidence_text = evidence_data[evid_id]\n",
        "      eval_pair_data.append({\"text\": claim_text + \" [SEP] \" + evidence_text, \"label\": label})\n",
        "\n",
        "eval_dataset = Dataset.from_list(eval_pair_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kjwLtdp_8Hy"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess(example):\n",
        "  return tokenizer(example['text'], truncation=True, padding='max_length')\n",
        "\n",
        "encoded_eval_dataset = eval_dataset.map(preprocess, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I6e1HvRACyN"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
        "\n",
        "outputs = trainer.predict(encoded_eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jniNKCVAK4-"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(outputs.predictions, axis=1)\n",
        "y_true = outputs.label_ids\n",
        "\n",
        "inv_label_map = {v: k for k, v in label_map.items()}\n",
        "target_names = [inv_label_map[i] for i in sorted(inv_label_map)]\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=target_names, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuFZL64oCQJ2"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"/content/bert-classifier\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUraxZriC0TQ"
      },
      "outputs": [],
      "source": [
        "label_map = {0: \"SUPPORTS\", 1: \"REFUTES\", 2: \"NOT_ENOUGH_INFO\", 3: \"DISPUTED\"}\n",
        "predictions = {}\n",
        "\n",
        "for claim_id, claim_info in train_labels_data.items():\n",
        "  claim_text = claim_info[\"claim_text\"]\n",
        "  evidence_ids = claim_info[\"evidences\"]\n",
        "\n",
        "    # Combine claim with each evidence\n",
        "  inputs = []\n",
        "  for evid_id in evidence_ids:\n",
        "    evidence_text = evidence_data.get(evid_id, \"\")\n",
        "    combined_text = claim_text + \" [SEP] \" + evidence_text\n",
        "    inputs.append(combined_text)\n",
        "\n",
        "  # Tokenize inputs\n",
        "  encodings = tokenizer(inputs, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "  # Get model predictions\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**encodings)\n",
        "    logits = outputs.logits\n",
        "    predicted_classes = torch.argmax(logits, dim=1)\n",
        "\n",
        "  # Majority vote if multiple evidences\n",
        "  predicted_class = torch.mode(predicted_classes).values.item()\n",
        "  predicted_label = label_map[predicted_class]\n",
        "\n",
        "  predictions[claim_id] = {\n",
        "      \"claim_label\": predicted_label,\n",
        "      \"evidences\": evidence_ids  # or select top-k based on your criteria\n",
        "  }\n",
        "\n",
        "# Save predictions to a JSON file\n",
        "with open(\"predictions.json\", \"w\") as f:\n",
        "  json.dump(predictions, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-taty-HDJDZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "encodings = {key: val.to(device) for key, val in encodings.items()}\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVBfNhnKDrvf"
      },
      "outputs": [],
      "source": [
        "!python eval.py --predictions predictions.json --groundtruth dev-claims.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}